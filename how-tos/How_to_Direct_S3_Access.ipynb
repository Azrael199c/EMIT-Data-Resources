{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to: Use Direct S3 Access to work with EMIT Data\n",
    "\n",
    "**Summary**  \n",
    "\n",
    "EMIT datasets are available through NASA's Earthdata Cloud. NASA Earthdata on Cloud is always free and accessible via either HTTPS or direct S3 bucket access. With direct S3 access, you can bring your \"code to the data\", making your processing faster and scalable. Direct S3 access to NASA Earthdata on Cloud is only available if your Amazon Web Services (AWS) instance is set up in the `us-west-2` region. This notebook explains how to utilize direct S3 access to EMIT data. \n",
    "\n",
    "**Requirements**\n",
    "\n",
    "+ A NASA [Earthdata Login](https://urs.earthdata.nasa.gov/) account is required to download EMIT data\n",
    "+ A configured `.netrc` file to access NASA Earth Data\n",
    "  + This can be configured in the first section of the `setup_instructions.md` included in the `/setup/` folder of the repository. \n",
    "+ Selected the `emit_tutorials` environment as the kernel for this notebook.\n",
    "  + For instructions on setting up the environment, follow the `setup_instructions.md` included in the `/setup/` folder of the repository. \n",
    "+ **xarray v2022.12.0** or newer to read s3 files twice when open with s3fs\n",
    "  + Version can be checked in Python using `xarray.__version__`\n",
    "  + To update, activate your environment and enter `pip install xarray==2022.12.0` in command line.\n",
    "\n",
    "**Learning Objectives**  \n",
    "+ How to use Direct S3 Access to EMIT Data\n",
    "+ How to add this functionality to any notebook from this repository\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import os\n",
    "import requests\n",
    "import s3fs\n",
    "import netCDF4 as nc\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "sys.path.append('../modules/')\n",
    "from emit_tools import emit_xarray"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Overview of s3 Access\n",
    "\n",
    "NASA Earthdata Cloud data in S3 can be directly accessed via temporary credentials; this access is limited to requests made within the US West (Oregon) (code: us-west-2) AWS region. Direct S3 access is achieved by passing NASA supplied temporary credentials to AWS so we can interact with S3 objects from applicable Earthdata Cloud buckets. For now, each NASA DAAC has different AWS credentials endpoints. Below are some of the credential endpoints to various DAACs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_cred_endpoint = {\n",
    "    'podaac':'https://archive.podaac.earthdata.nasa.gov/s3credentials',\n",
    "    'gesdisc': 'https://data.gesdisc.earthdata.nasa.gov/s3credentials',\n",
    "    'lpdaac':'https://data.lpdaac.earthdatacloud.nasa.gov/s3credentials',\n",
    "    'ornldaac': 'https://data.ornldaac.earthdata.nasa.gov/s3credentials',\n",
    "    'ghrcdaac': 'https://data.ghrc.earthdata.nasa.gov/s3credentials'\n",
    "}\n",
    "s3_cred_endpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to make a request to an endpoint for temporary credentials. Remember, each DAAC has their own endpoint and credentials are not usable for cloud data from other DAACs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Function \n",
    "def get_temp_creds(provider):\n",
    "    return requests.get(s3_cred_endpoint[provider]).json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Credentials\n",
    "temp_creds_req = get_temp_creds('lpdaac')\n",
    "#temp_creds_req"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up an s3fs Session for Direct Access\n",
    "\n",
    "`s3fs` sessions are used for authenticated access to s3 bucket and allows for typical file-system style operations. Below we create session by passing in the temporary credentials we recieved from our temporary credentials endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass Authentication to s3fs\n",
    "fs_s3 = s3fs.S3FileSystem(anon=False, \n",
    "                          key=temp_creds_req['accessKeyId'], \n",
    "                          secret=temp_creds_req['secretAccessKey'], \n",
    "                          token=temp_creds_req['sessionToken'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we specify the s3 URL to the data asset in Earthdata Cloud. This URL can be found via Earthdata Search or programmatically through the CMR and CMR-STAC APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define S3 URL                          \n",
    "s3_url = 's3://lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20220903T163129_2224611_012/EMIT_L2A_RFL_001_20220903T163129_2224611_012.nc'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open with the netCDF file using the s3fs package, then load the cloud asset into an xarray dataset, or use directly with `emit_xarray` function from `emit_tools`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = fs_s3.open(s3_url, mode='rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open s3 url\n",
    "fp = fs_s3.open(s3_url, mode='rb')\n",
    "# Open dataset with xarray\n",
    "ds = xr.open_dataset(fp)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and Orthorectify\n",
    "ds = emit_xarray(fp)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Spatially\n",
    "ds.isel(bands=40).hvplot.image(cmap='viridis', aspect = 'equal', frame_width=500, rasterize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Spectra at a Location\n",
    "ds.sel(longitude=-61.833,latitude=-39.710,method='nearest').hvplot.line(y='reflectance',x='wavelengths', color='black', frame_width=400)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## S3 Access for any Notebook in this Repository\n",
    "\n",
    "Add the two code blocks below to any how-to or tutorial, by replacing the block that sets the local filepath(s) as `fp` with the two blocks below. The first block imports the additional packages required and retrieves temporary s3 credentials. The second uses `s3fs` to open the desired s3 URL and create an object readable by `xarray`.\n",
    "\n",
    "**If you are on an openscapes 2i2c JupyterLab instance, check that xarray version is 2022.12.0**\n",
    "\n",
    "To do check version type the following in the terminal:  \n",
    "\n",
    "> `conda list`\n",
    "\n",
    "To install xarray version 2022.12.0 type the following in the terminal:  \n",
    "\n",
    "> `pip install xarray==2022.12.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import s3fs\n",
    "temp_creds_req = requests.get('https://data.lpdaac.earthdatacloud.nasa.gov/s3credentials').json() # use lpdaac credential endpoint for EMIT data\n",
    "# Create s3fs session\n",
    "fs_s3 = s3fs.S3FileSystem(anon=False, \n",
    "                          key=temp_creds_req['accessKeyId'], \n",
    "                          secret=temp_creds_req['secretAccessKey'], \n",
    "                          token=temp_creds_req['sessionToken'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set s3 url and open\n",
    "s3_url = 's3://lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20220903T163129_2224611_012/EMIT_L2A_RFL_001_20220903T163129_2224611_012.nc' # S3 URL to L2A Reflectance File used throughout tutorial\n",
    "#s3_url_mask = 's3://lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20220903T163129_2224611_012/EMIT_L2A_MASK_001_20220903T163129_2224611_012.nc' # Only used for Quality How-to\n",
    "fp = fs_s3.open(s3_url, mode='rb')\n",
    "#fp_mask = fs_s3.open(s3_url_mask, mode='rb') # Only used for Quality How-to"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Contact Info:  \n",
    "\n",
    "Email: LPDAAC@usgs.gov  \n",
    "Voice: +1-866-573-3222  \n",
    "Organization: Land Processes Distributed Active Archive Center (LP DAAC)¹  \n",
    "Website: <https://lpdaac.usgs.gov/>  \n",
    "Date last modified: 01-09-2023  \n",
    "\n",
    "¹Work performed under USGS contract G15PD00467 for NASA contract NNG14HH33I.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openscapes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:41:22) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3292b2aceff7d39327a7519422d4180a7c9b133202090f26e797e3dd8f2c7877"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
